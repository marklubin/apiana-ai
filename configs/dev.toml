# Development Configuration
# Uses Ollama on a separate development server or different port

[general]
environment = "dev"
batch_size = 20
output_base_dir = "output"

[prompt]
name = "default"
system_prompt_file = "prompts/self-reflective-system-message.txt"
user_prompt_template_file = "prompts/self-reflective-prompt-template.txt"

[llm_provider]
# Remote Ollama instance (example: on dev server)
model = "llama3.2"
base_url = "http://dev-server:11434/v1"  # TODO: Update with actual dev server URL
api_key = "ollama"
temperature = 0.7
max_tokens = 4096

[embedder]
# Local embeddings (could also be remote)
type = "local"
model = "nomic-ai/nomic-embed-text-v1"
dimension = 768

[neo4j]
# Shared development Neo4j instance
uri = "bolt://dev-neo4j:7687"  # TODO: Update with actual dev Neo4j URL
username = "neo4j"
password = "dev-password"  # TODO: Use secure password management
# database = "apiana_dev"